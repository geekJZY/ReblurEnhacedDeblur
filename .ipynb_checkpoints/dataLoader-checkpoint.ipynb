{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "This is a data loader for reblur project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import itertools\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os.path\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import sys\n",
    "#sys.path.append(\"./DeblurGAN\")\n",
    "sys.path.append(\"./DeblurGAN/data\")\n",
    "from base_dataset import BaseDataset\n",
    "from image_folder import make_dataset\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample of our dataset is formed like a dict {'image1': (t-2)th image, 'image2': (t-1)th image, 'image3': (t)th image, 'image3': (t+1)th image, 'image4': (t+2)th image, 'imageSharp': sharp image of (t)th image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deblurDataSet(Dataset):\n",
    "    \"\"\"Deblur dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, blur_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            blur_file(\"blur\" or \"blur_gamma\"): denote two different types of blur\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.blur_file = blur_file\n",
    "        self.transform = transform\n",
    "        self.folders = sorted(os.listdir(root_dir))\n",
    "        foldersLen = []\n",
    "        foldersStart = []\n",
    "        for folder in self.folders:\n",
    "            tempList = sorted(os.listdir(os.path.join(root_dir, folder, blur_file)))\n",
    "            foldersLen.append(len(tempList))\n",
    "            foldersStart.append(int(tempList[0].split('.')[0]))\n",
    "        self.foldersLen = foldersLen\n",
    "        self.foldersStart = foldersStart\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.foldersLen) - 4 * len(self.foldersLen)\n",
    "\n",
    "    def __getitem__(self, offset):\n",
    "        images = []\n",
    "        sample = {}\n",
    "        cnt = 0\n",
    "        offset = offset + 1\n",
    "        while offset > 0:\n",
    "            offset = offset - self.foldersLen[cnt] + 4\n",
    "            cnt = cnt + 1\n",
    "        cnt = cnt - 1\n",
    "        offset = offset + self.foldersLen[cnt] - 5\n",
    "        for index in range(5):\n",
    "            img_name = os.path.join(self.root_dir, self.folders[cnt], self.blur_file\n",
    "                                ,str(self.foldersStart[cnt]+offset+index).zfill(6)+\".png\")\n",
    "            images.append(io.imread(img_name))\n",
    "            sample['image'+str(index)] = images[index]\n",
    "        label_name = os.path.join(os.path.join(self.root_dir, self.folders[cnt], \"sharp\"\n",
    "                                ,str(self.foldersStart[cnt]+offset+2).zfill(6)+\".png\"))\n",
    "        sample['label'] = io.imread(label_name)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample \n",
    "\n",
    "class GoproDataloader():\n",
    "    \n",
    "        def __init__(self, root_dir, blur_file, transform=None):\n",
    "\n",
    "        \n",
    "            self.root_dir = root_dir\n",
    "            self.blur_file = blur_file\n",
    "            self.transform = transform\n",
    "            self.folders = sorted(os.listdir(root_dir))\n",
    "            foldersLen = []\n",
    "            foldersStart = []\n",
    "            for folder in self.folders:\n",
    "                tempList = sorted(os.listdir(os.path.join(root_dir, folder, blur_file)))\n",
    "                foldersLen.append(len(tempList))\n",
    "                foldersStart.append(int(tempList[0].split('.')[0]))\n",
    "            self.foldersLen = foldersLen\n",
    "            self.foldersStart = foldersStart\n",
    "        \n",
    "        def __getitem__(self, offset):\n",
    "            \n",
    "            images = []\n",
    "            sample = {}\n",
    "            cnt = 0\n",
    "            offset = offset + 1\n",
    "            while offset > 0:\n",
    "                offset = offset - self.foldersLen[cnt] + 4\n",
    "                cnt = cnt + 1\n",
    "            cnt = cnt - 1\n",
    "            offset = offset + self.foldersLen[cnt] - 5\n",
    "            #for index in range(5):\n",
    "            img_name = os.path.join(self.root_dir, self.folders[cnt], self.blur_file\n",
    "                                ,str(self.foldersStart[cnt]+offset).zfill(6)+\".png\")\n",
    "            img=io.imread(img_name)\n",
    "            images.append(io.imread(img_name))\n",
    "            #sample['image'+str(index)] = images[index]\n",
    "            label_name = os.path.join(os.path.join(self.root_dir, self.folders[cnt], \"sharp\"\n",
    "                                    ,str(self.foldersStart[cnt]+offset+2).zfill(6)+\".png\"))\n",
    "            label=io.imread(label_name)\n",
    "            sample['label'] = io.imread(label_name)\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "\n",
    "            return img, label\n",
    "        \n",
    "        \n",
    "        def __len__(self):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"normalize the images to [-1,1].\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        return {key:(sample[key].astype(float) - 128)/128 for key in sample}\n",
    "\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        return {key:torch.from_numpy(sample[key].transpose((2, 0, 1))) for key in sample}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/karthik/Desktop/Spring18/ml/code/deblur-gan/GOPRO_Large/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-125bb066a176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtoTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m dataset = deblurDataSet(\"/home/karthik/Desktop/Spring18/ml/code/deblur-gan/GOPRO_Large/train\",\n\u001b[0;32m----> 4\u001b[0;31m                         \"blur\",transforms.Compose([norm,toTensor]))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoldersLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8a5603ec47f3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, blur_file, transform)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblur_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblur_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mfoldersLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfoldersStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/karthik/Desktop/Spring18/ml/code/deblur-gan/GOPRO_Large/train'"
     ]
    }
   ],
   "source": [
    "norm = Normalize()\n",
    "toTensor = ToTensor()\n",
    "dataset = deblurDataSet(\"/scratch/user/jiangziyu/data/GOPRO_Large/train/\",\n",
    "                        \"blur\",transforms.Compose([norm,toTensor]))\n",
    "print(len(dataset))\n",
    "print(dataset.foldersLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data and draw it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= GoproDataloader(\"/home/karthik/Desktop/Spring18/ml/code/deblur-gan/GOPRO_Large/train\",\n",
    "                        \"blur\",transforms.Compose([norm,toTensor]))\n",
    "i,l= g.__getitem__(7)\n",
    "\n",
    "\n",
    "plt.imshow(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plt.imshow(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = dataset[80]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "for i in range(5):\n",
    "    image = ((sample['image'+str(i)].numpy()+1)/2).transpose((1, 2, 0))\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    print(image.shape)\n",
    "    \n",
    "    ax.set_title('Blur image #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "ax = plt.subplot(2, 3, 6)\n",
    "plt.tight_layout()\n",
    "ax.set_title('Sharp image')\n",
    "ax.axis('off')\n",
    "plt.imshow(((sample['label'].numpy()+1)/2).transpose((1, 2, 0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=4,\n",
    "#                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeblurGAN\n",
    "* import the deblurGAN with its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./DeblurGAN')\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import DeblurGAN.util.util as util\n",
    "from DeblurGAN.models.base_model import BaseModel\n",
    "from DeblurGAN.options.test_options import TestOptions\n",
    "from DeblurGAN.models import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['test.py', '--dataroot', './DeblurGAN/dataCombine', '--model', 'test', '--dataset_mode', 'single', '--learn_residual', '--resize_or_crop', 'scale_width']\n",
    "opt = TestOptions().parse()\n",
    "opt.nThreads = 1   # test code only supports nThreads = 1\n",
    "opt.batchSize = 1  # test code only supports batchSize = 1\n",
    "opt.serial_batches = True  # no shuffle\n",
    "opt.no_flip = True  # no flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset=AlignedDataset()\n",
    "# dataloader = DataLoader(dataset, batch_size=4,\n",
    "#                        shuffle=True, num_workers=4)\n",
    "\n",
    "def CreateDataLoader(opt):\n",
    "    from data.custom_dataset_data_loader import CustomDatasetDataLoader\n",
    "    data_loader = CustomDatasetDataLoader()\n",
    "    print(data_loader.name())\n",
    "    data_loader.initialize(opt)\n",
    "    return data_loader\n",
    "\n",
    "dataloader=CreateDataLoader(opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the blur and the deblur network weights from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DeblurGAN/./checkpoints/experiment_name/latest_net_G.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d48a025b9e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mload_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG_deblur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------- Networks initialized -------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d48a025b9e03>\u001b[0m in \u001b[0;36mload_network\u001b[0;34m(network, network_label, epoch_label, blur_network, blur_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DeblurGAN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoints_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/user/jiangziyu/.conda/envs/ML/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DeblurGAN/./checkpoints/experiment_name/latest_net_G.pth'"
     ]
    }
   ],
   "source": [
    "def load_network( network, network_label, epoch_label, blur_network=False, blur_epoch=69):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        blur_dir=\"weights_blur_epoch_%s\"%blur_epoch\n",
    "        \n",
    "        if blur_network==True:\n",
    "            sys.argv[-1]=0\n",
    "            network=torch.nn.DataParallel(network).cuda()\n",
    "            save_path=os.path.join(\"DeblurGAN\",opt.checkpoints_dir, opt.name,blur_dir, save_filename)\n",
    "        else:\n",
    "            save_path = os.path.join(\"DeblurGAN\",opt.checkpoints_dir, opt.name, save_filename)            \n",
    "        network.load_state_dict(torch.load(save_path))\n",
    "\n",
    "\n",
    "netG_deblur= networks.define_G(opt.input_nc, opt.output_nc, opt.ngf,opt.which_model_netG, opt.norm, not opt.no_dropout, opt.gpu_ids, False,\n",
    "                                      opt.learn_residual)\n",
    "\n",
    "\n",
    "load_network(netG_deblur, 'G', opt.which_epoch)\n",
    "\n",
    "print('---------- Networks initialized -------------')\n",
    "networks.print_network(netG_deblur)\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "\"\"\"load the blur network\"\"\"\n",
    "netG_blur = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf,\n",
    "                                     opt.which_model_netG, opt.norm, not opt.no_dropout, opt.gpu_ids, False,\n",
    "                                     opt.learn_residual)\n",
    "load_network(netG_blur, 'G', opt.which_epoch, blur_network=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fine_tune_existing_layers(model,num_layers_frozen=19):\n",
    "\n",
    "    ct=0\n",
    "    for child in list(model.children())[0]:\n",
    "        ct+=1\n",
    "        if ct<num_layers_frozen:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "\n",
    "\n",
    "    print(\"Total number of layers are:\",ct,\",number of layers frozen are:\", num_layers_frozen)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class MyModel(nn.Module):\\n    def __init__(self, pretrained_model):\\n        self.pretrained_model = pretrained_model\\n        self.last_layer = ... # create layer\\n\\n    def forward(self, x):\\n        return self.last_layer(self.pretrained_model(x))\\n\\npretrained_model = torchvision.models.resnet18(pretrained=True)\\nmodel = MyModel(pretrained_model)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ADDING ADDITIONAL LAYERS TO PRETRAINED MODELS\n",
    "\n",
    "\"\"\"class MyModel(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.last_layer = ... # create layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.last_layer(self.pretrained_model(x))\n",
    "\n",
    "pretrained_model = torchvision.models.resnet18(pretrained=True)\n",
    "model = MyModel(pretrained_model)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the frozen generator models of netG_deblur and netG_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers are: 28 ,number of layers frozen are: 19\n",
      "Total number of layers are: 28 ,number of layers frozen are: 19\n"
     ]
    }
   ],
   "source": [
    "netG_frozen_deblur= fine_tune_existing_layers(netG_deblur, num_layers_frozen=19)\n",
    "netG_frozen_blur= fine_tune_existing_layers(netG_blur, num_layers_frozen=19)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define 2 models: First takes as input a blurry image and the second takes the sharp image as input\n",
    "\n",
    "#### CycleDeblurNet: blurry image -->DeblurNet -->sharp restored image -->blur net -->blurry restored image --> forward cycle consistency loss\n",
    "\n",
    "#### CycleblurNet: sharp image -->blurNet -->blurry restored image -->deblur net -->sharp restored image --> backward cycle consistency loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CycleDeblurNet(object):\n",
    "    \n",
    "    def __init__(self, deblur_net, blur_net):\n",
    "        \"\"\"init with the frozen versions of the blur net and the deblur net\"\"\"\n",
    "        super(CycleDeblurNet, self).__init__()\n",
    "        self.blur_net=blur_net\n",
    "        self.deblur_net=deblur_net\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x= self.deblur_net(x)\n",
    "        out= self.blur_net(x)\n",
    "        \n",
    "        return(out)\n",
    "    \n",
    "class CycleblurNet(object):\n",
    "    \n",
    "    def __init__(self, deblur_net, blur_net):\n",
    "        \"\"\"init with the frozen versions of the blur net and the deblur net\"\"\"\n",
    "        super(CycleblurNet, self).__init__()\n",
    "        self.blur_net=blur_net\n",
    "        self.deblur_net=deblur_net\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x= self.blur_net(x)\n",
    "        out=self.deblur_net(x)\n",
    "        \n",
    "        return(out)\n",
    "\n",
    "netA= CycleDeblurNet(netG_frozen_deblur, netG_frozen_blur)\n",
    "netB= CycleblurNet(netG_frozen_deblur, netG_frozen_blur)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epoch=7\n",
    "batch_size=1\n",
    "num_workers=4\n",
    "dataset_dir=\"../deblur-gan/GOPRO_Large/train/\"\n",
    "learning_rate=0.0002\n",
    "#transforms=None #make data augmentation. For now using only the transforms defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle consistency loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Quote from the paper about the loss function: For all the experiments, we set λ = 10 in Equation 3.\n",
    "We use the Adam solver [24] with a batch size of 1\"\"\"\n",
    "\n",
    "forward_cycle_consistency_criterion= torch.nn.L1Loss()\n",
    "backward_cycle_consistency_criterion=torch.nn.L1Loss()\n",
    "\n",
    "#criterion= forward_cycle_consistency_criterion+backward_cycle_consistency_criterion()\n",
    "\n",
    "#lambda_cycle is irrelevant for the moment as we use only cycle consistency loss as of now\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(filter(lambda p: p.requires_grad, netG_frozen_deblur.parameters()),\n",
    "filter(lambda p: p.requires_grad, netG_frozen_blur.parameters())), lr=learning_rate)\n",
    "\n",
    "###Get the data. dataloader already defined above\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size,\n",
    "#                         shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-04f75647d58b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got str"
     ]
    }
   ],
   "source": [
    "def CreateDataLoader(opt):\n",
    "    from data.custom_dataset_data_loader import CustomDatasetDataLoader\n",
    "    data_loader = CustomDatasetDataLoader()\n",
    "    print(data_loader.name())\n",
    "    data_loader.initialize(opt)\n",
    "    return data_loader\n",
    "\n",
    "dataloader=CreateDataLoader(opt)\n",
    "dataset = dataloader.load_data()\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i, (images, labels) in enumerate(dataset):\n",
    "        print(images, labels)\n",
    "        images=Variable(images).cuda()\n",
    "        labels=Variable(labels).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward loss part\n",
    "        deblur_model_outputs_f = CycleDeblurNet(images)\n",
    "        blur_model_outputs_f= CycleblurNet(deblur_model_outputs_f)\n",
    "        loss_f = forward_cycle_consistency_criterion(images, blur_model_outputs_f)\n",
    "        \n",
    "        #backward loss part\n",
    "        blur_model_outputs_b= CycleblurNet(labels)\n",
    "        deblur_model_outputs_b= CycleDeblurNet(blur_model_outputs_b)\n",
    "        loss_b= backward_cycle_consistency_criterion(labels, deblur_model_outputs_b)\n",
    "        \n",
    "        loss= loss_f + loss_b\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n",
      "A A_paths\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-ea71adfbc255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Spring18/ml/code/ReblurEnhacedDeblur/DeblurGAN/data/single_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mA_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mA_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mA_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;31m# initialize to unknown error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mload_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoderconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoderconfig\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;31m# create palette (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for (img, label) in dataloader.dataset:\n",
    "    print(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader.load_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
